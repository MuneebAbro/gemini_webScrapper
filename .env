
# Llama API Configuration
LLAMA_API_KEY=

# Optional: Override default model (default: llama-3.3-70b-versatile)
# LLAMA_MODEL=llama-3.3-70b-versatile

# Optional: Override default API URL (default: https://api.groq.com/openai/v1/chat/completions)
# LLAMA_API_URL=https://api.groq.com/openai/v1/chat/completions

# Rate Limiting Configuration (30 requests per minute = 2 seconds between requests)
 LLAMA_RATE_LIMIT_DELAY=3.0

# Scraping Configuration
MAX_PAGES=50
DELAY_BETWEEN_REQUESTS=1.0
USER_AGENT=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36

# Output Configuration
OUTPUT_DIR=knowledge_base
JSON_FILENAME=knowledge_base.json

# Content Processing
MIN_CONTENT_LENGTH=100
MAX_CONTENT_LENGTH=5000
MAX_TOKENS=1000